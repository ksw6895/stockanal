import os
import asyncio
import logging
from typing import Dict, List, Optional, Any
from google import genai
from google.genai import types
# Rich imports removed for server compatibility

# Console removed for server compatibility

class GeminiClient:
    def __init__(self, api_key: Optional[str] = None):
        self.logger = logging.getLogger(__name__)
        self.api_key = api_key or os.getenv('GOOGLE_API_KEY')
        
        if not self.api_key:
            raise ValueError("Google API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì—ì„œ GOOGLE_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        
        # Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = genai.Client(api_key=self.api_key)
        
        # ê¸°ë³¸ ì„¤ì •
        self.model_name = "gemini-2.5-flash"
        self.max_tokens = 8192
        self.temperature = 0.7
        
        console.print(f"[green]Gemini API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {self.model_name})[/green]")
    
    def generate_analysis(self, prompt: str, stock_data: Dict, 
                         thinking_enabled: bool = True, 
                         thinking_budget: int = 2048) -> str:
        """
        ì£¼ì‹ ë¶„ì„ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            prompt: ë¶„ì„ ìš”ì²­ í”„ë¡¬í”„íŠ¸
            stock_data: ì£¼ì‹ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
            thinking_enabled: ì‚¬ê³  ê³¼ì • í™œì„±í™” ì—¬ë¶€
            thinking_budget: ì‚¬ê³  ê³¼ì • í† í° ì˜ˆì‚°
        
        Returns:
            str: ìƒì„±ëœ ë¶„ì„ ë³´ê³ ì„œ
        """
        try:
            print("ğŸ¤– AI ë¶„ì„ ìš”ì²­ ì¤‘...")
            
            # ì£¼ì‹ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                formatted_data = self._format_stock_data(stock_data)
                
                # ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                full_prompt = f"""
{prompt}

**ë¶„ì„ ëŒ€ìƒ ì£¼ì‹ ë°ì´í„°:**
{formatted_data}

**ë¶„ì„ ìš”ì²­ì‚¬í•­:**
ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ ì£¼ì‹ì˜ ê°€ì¹˜íˆ¬ì ê´€ì ì—ì„œì˜ ì¢…í•©ì ì¸ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.
"""
                
                # ì„¤ì • êµ¬ì„±
                config = types.GenerateContentConfig(
                    temperature=self.temperature,
                    max_output_tokens=self.max_tokens,
                )
                
                # ì‚¬ê³  ê³¼ì • í™œì„±í™” ì‹œ ì„¤ì • ì¶”ê°€
                if thinking_enabled:
                    config.thinking_config = types.ThinkingConfig(
                        thinking_budget=thinking_budget
                    )
                
                # API í˜¸ì¶œ
                response = self.client.models.generate_content(
                    model=self.model_name,
                    contents=full_prompt,
                    config=config
                )
                
                progress.update(task, description="[green]AI ë¶„ì„ ì™„ë£Œ")
                
                if not response.text:
                    raise ValueError("AIë¡œë¶€í„° ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                
                return response.text
                
        except Exception as e:
            self.logger.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise Exception(f"AI ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
    
    def _format_stock_data(self, stock_data: Dict) -> str:
        """ì£¼ì‹ ë°ì´í„°ë¥¼ AIê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        try:
            symbol = stock_data.get('symbol', 'N/A')
            company_name = stock_data.get('company_name', 'N/A')
            sector = stock_data.get('sector', 'N/A')
            industry = stock_data.get('industry', 'N/A')
            current_price = stock_data.get('current_price', 0)
            market_cap = stock_data.get('market_cap', 0)
            metrics = stock_data.get('financial_metrics', {})
            
            # ì‹œê°€ì´ì•¡ì„ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜
            market_cap_str = self._format_currency(market_cap)
            
            formatted = f"""
## ê¸°ì—… ê¸°ë³¸ ì •ë³´
- ì¢…ëª© ì½”ë“œ: {symbol}
- ê¸°ì—…ëª…: {company_name}
- ì„¹í„°: {sector}
- ì‚°ì—…: {industry}
- í˜„ì¬ ì£¼ê°€: ${current_price:.2f}
- ì‹œê°€ì´ì•¡: {market_cap_str}

## ì£¼ìš” ì¬ë¬´ ì§€í‘œ
- PER (ì£¼ê°€ìˆ˜ìµë¹„ìœ¨): {metrics.get('pe_ratio', 0):.2f}
- PBR (ì£¼ê°€ìˆœìì‚°ë¹„ìœ¨): {metrics.get('pb_ratio', 0):.2f}
- ROE (ìê¸°ìë³¸ìˆ˜ìµë¥ ): {metrics.get('roe', 0):.2%}
- ROA (ì´ìì‚°ìˆ˜ìµë¥ ): {metrics.get('roa', 0):.2%}
- ë¶€ì±„ë¹„ìœ¨: {metrics.get('debt_to_equity', 0):.2f}
- ë°°ë‹¹ìˆ˜ìµë¥ : {metrics.get('dividend_yield', 0):.2%}
- ë§¤ì¶œì•¡ ì„±ì¥ë¥ : {metrics.get('revenue_growth', 0):.2f}%
- ìˆœì´ìµ ì„±ì¥ë¥ : {metrics.get('income_growth', 0):.2f}%

## ì£¼ê°€ ë° ìœ„í—˜ ì§€í‘œ
- 52ì£¼ ìµœê³ ê°€: ${metrics.get('52_week_high', 0):.2f}
- 52ì£¼ ìµœì €ê°€: ${metrics.get('52_week_low', 0):.2f}
- ë² íƒ€ê°’: {metrics.get('beta', 0):.2f}
- 30ì¼ ë³€ë™ì„±: {metrics.get('volatility_30d', 0):.2%}
- í‰ê·  ê±°ë˜ëŸ‰ (30ì¼): {metrics.get('avg_volume_30d', 0):,.0f}

## ì¬ë¬´ ê±´ì „ì„±
- í˜„ê¸ˆ ë° í˜„ê¸ˆì„± ìì‚°: {self._format_currency(metrics.get('cash_and_equivalents', 0))}
- ì´ ë¶€ì±„: {self._format_currency(metrics.get('total_debt', 0))}
- ììœ í˜„ê¸ˆíë¦„: {self._format_currency(metrics.get('free_cash_flow', 0))}
- ë°œí–‰ ì£¼ì‹ ìˆ˜: {metrics.get('shares_outstanding', 0):,.0f}
"""
            
            return formatted
            
        except Exception as e:
            self.logger.error(f"ì£¼ì‹ ë°ì´í„° í¬ë§·íŒ… ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return f"ì£¼ì‹ ë°ì´í„° í¬ë§·íŒ… ì˜¤ë¥˜: {str(e)}"
    
    def _format_currency(self, amount: float) -> str:
        """ìˆ«ìë¥¼ ì½ê¸° ì‰¬ìš´ í†µí™” í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        if amount == 0:
            return "$0"
        
        if amount >= 1e12:
            return f"${amount/1e12:.2f}T"
        elif amount >= 1e9:
            return f"${amount/1e9:.2f}B"
        elif amount >= 1e6:
            return f"${amount/1e6:.2f}M"
        elif amount >= 1e3:
            return f"${amount/1e3:.2f}K"
        else:
            return f"${amount:.2f}"
    
    def generate_comparison_analysis(self, stocks_data: Dict[str, Dict], 
                                   custom_prompt: Optional[str] = None) -> str:
        """
        ì—¬ëŸ¬ ì£¼ì‹ì„ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            stocks_data: ì¢…ëª©ë³„ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
            custom_prompt: ì‚¬ìš©ì ì§€ì • í”„ë¡¬í”„íŠ¸
        
        Returns:
            str: ë¹„êµ ë¶„ì„ ë³´ê³ ì„œ
        """
        try:
            symbols = list(stocks_data.keys())
            
            if len(symbols) < 2:
                raise ValueError("ë¹„êµ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 2ê°œì˜ ì¢…ëª©ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            
            # ê¸°ë³¸ ë¹„êµ ë¶„ì„ í”„ë¡¬í”„íŠ¸
            default_prompt = f"""
ë‹¤ìŒ {len(symbols)}ê°œ ì¢…ëª©({', '.join(symbols)})ì— ëŒ€í•œ ê°€ì¹˜íˆ¬ì ê´€ì ì—ì„œì˜ ë¹„êµ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.

**ë¶„ì„ ìš”ì²­ì‚¬í•­:**
1. ê° ì¢…ëª©ì˜ ê°€ì¹˜íˆ¬ì ë§¤ë ¥ë„ í‰ê°€
2. ì¬ë¬´ ê±´ì „ì„± ë¹„êµ
3. ì„±ì¥ì„± ë° ìˆ˜ìµì„± ë¶„ì„
4. ìœ„í—˜ ìš”ì¸ ë¶„ì„
5. í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ì‹œ ê³ ë ¤ì‚¬í•­
6. ìµœì¢… íˆ¬ì ìš°ì„ ìˆœìœ„ ë° ì´ìœ 

ê° ì¢…ëª©ì˜ ê°•ì ê³¼ ì•½ì ì„ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì œì‹œí•˜ê³ , 
ê°€ì¹˜íˆ¬ììê°€ ì¤‘ìš”í•˜ê²Œ ê³ ë ¤í•´ì•¼ í•  ìš”ì†Œë“¤ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
"""
            
            prompt = custom_prompt or default_prompt
            
            # ëª¨ë“  ì¢…ëª© ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©
            all_data = ""
            for symbol, data in stocks_data.items():
                all_data += f"\n{'='*50}\n"
                all_data += f"ì¢…ëª©: {symbol}\n"
                all_data += f"{'='*50}\n"
                all_data += self._format_stock_data(data)
                all_data += "\n"
            
            full_prompt = f"""
{prompt}

**ë¶„ì„ ëŒ€ìƒ ì¢…ëª©ë“¤ì˜ ë°ì´í„°:**
{all_data}
"""
            
            # ë¹„êµ ë¶„ì„ì€ ë” ë§ì€ í† í°ì´ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì„¤ì • ì¡°ì •
            config = types.GenerateContentConfig(
                temperature=self.temperature,
                max_output_tokens=self.max_tokens * 2,  # ë” ê¸´ ì‘ë‹µ í—ˆìš©
                thinking_config=types.ThinkingConfig(
                    thinking_budget=4096  # ë” ë§ì€ ì‚¬ê³  ê³¼ì • í† í°
                )
            )
            
            print("ğŸ”„ ë¹„êµ ë¶„ì„ ì¤‘...")
            
            response = self.client.models.generate_content(
                    model=self.model_name,
                    contents=full_prompt,
                    config=config
                )
                
                progress.update(task, description="[green]ë¹„êµ ë¶„ì„ ì™„ë£Œ")
                
                if not response.text:
                    raise ValueError("AIë¡œë¶€í„° ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                
                return response.text
                
        except Exception as e:
            self.logger.error(f"ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise Exception(f"ë¹„êµ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
    
    def test_connection(self) -> bool:
        """API ì—°ê²° ìƒíƒœë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
        try:
            console.print("[cyan]API ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...[/cyan]")
            
            response = self.client.models.generate_content(
                model=self.model_name,
                contents="Hello, this is a connection test. Please respond with 'Connection successful.'",
                config=types.GenerateContentConfig(
                    max_output_tokens=50,
                    temperature=0.1
                )
            )
            
            if response.text and "successful" in response.text.lower():
                console.print("[green]âœ“ API ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ[/green]")
                return True
            else:
                console.print("[red]âœ— API ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨[/red]")
                return False
                
        except Exception as e:
            console.print(f"[red]âœ— API ì—°ê²° í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}[/red]")
            return False
    
    def set_model_parameters(self, model_name: Optional[str] = None, 
                           max_tokens: Optional[int] = None, 
                           temperature: Optional[float] = None):
        """ëª¨ë¸ ë§¤ê°œë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
        if model_name:
            self.model_name = model_name
        if max_tokens:
            self.max_tokens = max_tokens
        if temperature is not None:
            self.temperature = temperature
            
        console.print(f"[blue]ëª¨ë¸ ì„¤ì • ì—…ë°ì´íŠ¸: {self.model_name}, "
                     f"max_tokens={self.max_tokens}, temperature={self.temperature}[/blue]")